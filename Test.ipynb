{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "257a7961-a86c-43ab-9176-a933f999abe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from collections import defaultdict\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer as tok\n",
    "from transformers import GPT2LMHeadModel as head\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fe6e88c-00b7-4074-9372-f43e16fbf24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4723bff8-854c-4649-9829-ed4f56889ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = lambda d, l='english': nltk.tokenize.word_tokenize(d, language=l, preserve_line=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cd62c72-565a-49c3-a1f6-92b7adc5423a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Citation: Zeman, Daniel; et al., 2024, \n",
    "  Universal Dependencies 2.15, LINDAT/CLARIAH-CZ digital library at the Institute of Formal and Applied Linguistics (ÃšFAL), Faculty of Mathematics and Physics, Charles University, \n",
    "  http://hdl.handle.net/11234/1-5787.\n",
    "\"\"\"\n",
    "eng_data = open(\"ud-215/ud-treebanks-v2.15/UD_English-GUM/en_gum-ud-train.txt\").read()\n",
    "ngrams = nltk.ngrams(tok(eng_data), N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82b4c26c-43e4-4ecf-81b3-7cbd853ef193",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162760it [00:00, 1735219.68it/s]\n"
     ]
    }
   ],
   "source": [
    "table = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for bigram in tqdm.tqdm(ngrams):\n",
    "    w1, w2 = bigram\n",
    "    table[w1][w2] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b5f3226-6544-4fd9-a625-1b1fecbe9e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_data_test = open(\"ud-215/ud-treebanks-v2.15/UD_English-GUM/en_gum-ud-test.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dca2e726-a0d2-4135-8ebd-c5c9361c3098",
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity = 1\n",
    "for bigram in nltk.ngrams(tok(eng_data_test), N):\n",
    "    w1, w2 = bigram\n",
    "    if table[w1][w2] == 0:\n",
    "        perplexity *= 2\n",
    "    else:\n",
    "        perplexity *= max(1 / (table[w1][w2] / (sum(table[w1].values()))), 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c72361d-4c90-4d82-85ae-1de1af05aa60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "55913028-55b4-48e8-8ea2-0a33eeb56ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = head.from_pretrained('gpt2')\n",
    "tokenizer = tok.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ab8129-4625-44a5-b610-e65a4e35ab5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a5ee8387-7472-41fc-9058-0c53131fa92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = '<|endoftext|>The coach smiled at the player tossed a frisbee.'\n",
    "s2 = '<|endoftext|>L\\'allenatore sorrise al giocatore che aveva lanciato il frisbee.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9ebb0e97-1d9d-400a-95e2-fafe0042019b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.6199e-04, 2.4113e-02, 9.5428e-04,  ..., 1.5595e-08, 1.2056e-08,\n",
       "         1.9246e-03],\n",
       "        [4.5156e-07, 4.0817e-06, 8.7872e-07,  ..., 6.5628e-07, 2.2708e-08,\n",
       "         4.6907e-06],\n",
       "        [2.8929e-05, 3.3060e-05, 6.8108e-07,  ..., 4.3267e-09, 6.2591e-06,\n",
       "         1.0636e-05],\n",
       "        ...,\n",
       "        [9.7112e-09, 1.7678e-09, 1.0148e-11,  ..., 4.9267e-15, 3.0244e-12,\n",
       "         5.4265e-09],\n",
       "        [1.3881e-04, 4.8386e-05, 1.2973e-07,  ..., 4.3097e-09, 5.6733e-08,\n",
       "         1.8539e-05],\n",
       "        [5.8190e-07, 2.5833e-05, 2.2614e-07,  ..., 1.1884e-11, 3.3631e-11,\n",
       "         4.2481e-03]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate(token_ids):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(token_ids)\n",
    "    softmax = torch.nn.Softmax(dim=-1) \n",
    "    return softmax(output.logits).squeeze(0)\n",
    "    \n",
    "token_ids = torch.Tensor(tokenizer.encode(s1)).int()\n",
    "evaluate(token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f5d3fc40-6cb3-4789-8b82-74cef3565dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12.4271)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def log_prefix_probability(s, i):\n",
    "    toks = tokenizer.encode(s)\n",
    "    sx = evaluate(torch.Tensor(toks).int())\n",
    "\n",
    "    return sum(torch.log(sx[j][toks[j + 1]]) for j in range(i))\n",
    "\n",
    "-(log_prefix_probability(s1, 7) - log_prefix_probability(s1, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b697a7ac-ab91-4096-a4df-3922c5bc352c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-30.7355)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_prefix_probability(s1, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "654d1e3f-d05f-44d6-9eda-2ffb2429a0f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-37.2877)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_prefix_probability(s2, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3475fbcf-6e69-425a-91e0-1bdfd29553e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Surprisal:\n",
    "    def __init__(self, model_name, input_file):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name, output_hidden_states=True)\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "    def evaluate(token_ids):\n",
    "        with torch.no_grad():\n",
    "            output = model(token_ids)\n",
    "        softmax = torch.nn.Softmax(dim=-1) \n",
    "        return softmax(output.logits).squeeze(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
